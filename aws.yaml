tosca_definitions_version: cloudify_dsl_1_3

description: >
  This blueprint creates a Kubernetes Cluster.

imports:
  - http://www.getcloudify.org/spec/cloudify/4.3/types.yaml
  - plugin:cloudify-diamond-plugin
  - plugin:cloudify-fabric-plugin
  - plugin:cloudify-utilities-plugin
  - plugin:cloudify-aws-plugin
  - imports/kubernetes.yaml
  - imports/cloud-config.yaml

inputs:

  ami:
    description: >
      An AWS AMI. Tested with a Centos 7.0 image.
    default: { get_secret: centos_core_image }

  instance_type:
    description: >
      The AWS instance_type. Tested with m3.medium, although that is unnecessarily large.
    default: t2.medium

  agent_user:
    description: >
      The username of the agent running on the instance created from the image.
    default: ec2-user

  node_security_group:
    description: >
      The resource id of the security group

  node_ssh_group:
    description: >
      The resource id of the ssh security group

dsl_definitions:

  client_config: &client_config
    aws_access_key_id: { get_secret: aws_access_key_id }
    aws_secret_access_key: { get_secret: aws_secret_access_key }
    region_name: { get_secret: ec2_region_name }

node_templates:

  k8s_node_host:
    type: cloudify.nodes.aws.ec2.Instances
    properties:
      agent_config:
        install_method: remote
        user: { get_input: agent_user }
        port: 22
        key: { get_secret: agent_key_private }
      resource_config:
        ImageId: { get_input: ami }
        InstanceType: { get_input: instance_type }
        kwargs:
          Placement: { get_secret: availability_zone }
          UserData: { get_attribute: [ cloudify_host_cloud_config, cloud_config ] }
      client_config: *client_config
      Tags:
        - Key: Name
          Value: KubernetesNodeHost
    interfaces:
      cloudify.interfaces.monitoring_agent:
        install:
          implementation: diamond.diamond_agent.tasks.install
          inputs:
            diamond_config:
              interval: 1
        start: diamond.diamond_agent.tasks.start
        stop: diamond.diamond_agent.tasks.stop
        uninstall: diamond.diamond_agent.tasks.uninstall
      cloudify.interfaces.monitoring:
        start:
          implementation: diamond.diamond_agent.tasks.add_collectors
          inputs:
            collectors_config:
              ProcessResourcesCollector:
                config:
                  enabled: true
                  unit: B
                  measure_collector_time: true
                  cpu_interval: 0.5
                  process:
                    hyperkube:
                      name: hyperkube
    relationships:
      - type: cloudify.relationships.depends_on
        target: kubernetes_node_nic
      - type: cloudify.relationships.depends_on
        target: cloudify_host_cloud_config

  kubernetes_node_nic:
    type: cloudify.nodes.aws.ec2.Interface
    properties:
      client_config: *client_config
      resource_config:
        kwargs:
          Description: A NIC for Kubernetes Node.
          SubnetId: { get_secret: public_subnet_id }
          Groups:
            - { get_input: node_security_group }
            - { get_input: node_ssh_group }
      Tags:
        - Key: Name
          Value: KubernetesNodeNic

groups:

  k8s_node_group:
    members:
      - k8s_node_host
      - kubernetes_node_nic

policies:

  kubernetes_node_vms_scaling_policy:
    type: cloudify.policies.scaling
    properties:
      default_instances:  1
    targets: [k8s_node_group]

outputs:

  deployment-type:
    description: Deployment Type, Needed In order to determine if the kubernetes host is normal node or load balancer
    value: node

  deployment-node-data-type:
    description: Cloudify node type needed in kubernetes cloudify provider
    value: cloudify.nodes.ApplicationServer.kubernetes.Node
