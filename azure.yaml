tosca_definitions_version: cloudify_dsl_1_3

description: >
  This blueprint creates a Kubernetes Cluster.
  It is based on this documentation: https://kubernetes.io/docs/getting-started-guides/kubeadm/

imports:
  - http://www.getcloudify.org/spec/cloudify/4.3/types.yaml
  - plugin:cloudify-azure-plugin
  - plugin:cloudify-diamond-plugin
  - plugin:cloudify-fabric-plugin
  - plugin:cloudify-utilities-plugin
  - imports/kubernetes.yaml

inputs:

  resource_prefix:
    default: k8s

  resource_suffix:
    default: '0'

  retry_after:
    type: integer
    default: 60

  size:
    default: Standard_A3

  node_storage_account_id:
    description: >
      The resource id/name node storage account

  image:
    default:
      publisher: OpenLogic
      offer: CentOS
      sku: '7.3'
      version: latest

  agent_user:
    description: The user name of the agent on the instance created from the image.
    default: docker # currently this is required

  ssh_public_keys:
    description: the public key
    default:
    - path: {concat:[ '/home/', { get_input: agent_user }, '/.ssh/authorized_keys' ]}
      keyData: { get_secret: agent_key_public }

dsl_definitions:

  azure_config: &azure_config
    subscription_id: { get_secret: subscription_id }
    tenant_id: { get_secret: tenant_id }
    client_id: { get_secret: client_id }
    client_secret: { get_secret: client_secret }

node_templates:

  k8s_node_docker:
    type: cloudify.azure.nodes.compute.VirtualMachineExtension
    properties:
      location: { get_secret: location }
      retry_after: { get_input: retry_after }
      azure_config: *azure_config
    interfaces:
      cloudify.interfaces.lifecycle:
        create:
          inputs:
            resource_config:
              publisher: Microsoft.Azure.Extensions
              type: CustomScript
              typeHandlerVersion: '2.0'
              autoUpgradeMinorVersion: true
              settings:
                commandToExecute:
                  concat:
                    - |
                      cat <<EOF > /etc/yum.repos.d/docker.repo
                      [dockerrepo]
                      name=Docker Repository
                      baseurl=https://yum.dockerproject.org/repo/main/centos/7
                      enabled=1
                      gpgcheck=1
                      gpgkey=https://yum.dockerproject.org/gpg
                      EOF
                    - |
                      cat <<EOF > /etc/yum.repos.d/kubernetes.repo
                      [kubernetes]
                      name=Kubernetes
                      baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
                      enabled=1
                      gpgcheck=1
                      repo_gpgcheck=1
                      gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg
                              https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
                      EOF
                      setenforce 0
                    - |
                      yum -t -y install docker-1.12.6 kubelet-1.9.6-0 kubeadm-1.9.6-0 kubectl-1.9.6-0 kubernetes-cni-0.6.0-0 ca-certificates
                      update-ca-trust force-enable
                      swapon -s | awk '{print "sudo swapoff " $1}' | grep -v "Filename" | sh -
                      sed -i 's|cgroup-driver=systemd|cgroup-driver=systemd --provider-id='`hostname`'|g' /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
                      sed -i 's|/usr/bin/dockerd|/usr/bin/dockerd --exec-opt native.cgroupdriver=systemd|g' /usr/lib/systemd/system/docker.service
                      systemctl enable docker && systemctl start docker
                      systemctl enable kubelet && systemctl start kubelet
                      iptables --flush
                      iptables -tnat --flush
                      mkdir -p /tmp/data
                      chcon -Rt svirt_sandbox_file_t /tmp/data
    relationships:
    - type: cloudify.azure.relationships.vmx_contained_in_vm
      target: k8s_node_host

  k8s_node_host:
    type: cloudify.azure.nodes.compute.VirtualMachine
    properties:
      location: { get_secret: location }
      retry_after: { get_input: retry_after }
      os_family: linux
      azure_config: *azure_config
      resource_config:
        hardwareProfile:
          vmSize: { get_input: size }
        storageProfile:
          imageReference: { get_input: image}
        osProfile:
          customData: |
            #!/bin/bash
            echo "hello"
          adminUsername: { get_input: agent_user }
          adminPassword: ''
          linuxConfiguration:
            ssh:
              publicKeys: { get_input: ssh_public_keys }
            disablePasswordAuthentication: true
      agent_config:
        user: { get_input: agent_user }
        install_method: remote
        port: 22
        key: { get_secret: agent_key_private }
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group
    - type: cloudify.azure.relationships.connected_to_storage_account
      target: storage_account
    - type: cloudify.azure.relationships.connected_to_availability_set
      target: availability_set
    - type: cloudify.azure.relationships.connected_to_nic
      target: kubernetes_node_host_nic
    interfaces:
      cloudify.interfaces.monitoring_agent:
        install:
          implementation: diamond.diamond_agent.tasks.install
          inputs:
            diamond_config:
              interval: 1
        start: diamond.diamond_agent.tasks.start
        stop: diamond.diamond_agent.tasks.stop
        uninstall: diamond.diamond_agent.tasks.uninstall
      cloudify.interfaces.monitoring:
        start:
          implementation: diamond.diamond_agent.tasks.add_collectors
          inputs:
            collectors_config:
              ProcessResourcesCollector:
                config:
                  enabled: true
                  unit: B
                  measure_collector_time: true
                  cpu_interval: 0.5
                  process:
                    hyperkube:
                      name: hyperkube

  network_security_group:
    type: cloudify.azure.nodes.network.NetworkSecurityGroup
    properties:
      name: {concat:[{get_input: resource_prefix},nsg,{get_input: resource_suffix}]}
      location: { get_secret: location }
      azure_config: *azure_config
      use_external_resource: true
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group

  availability_set:
    type: cloudify.azure.nodes.compute.AvailabilitySet
    properties:
      name: {concat:[{get_input: resource_prefix},availset,{get_input: resource_suffix}]}
      location: { get_secret: location }
      azure_config: *azure_config
      use_external_resource: true
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group

  kubernetes_node_host_nic:
    type: cloudify.azure.nodes.network.NetworkInterfaceCard
    properties:
      location: { get_secret: location }
      azure_config: *azure_config
      retry_after: { get_input: retry_after }
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group
    - type: cloudify.azure.relationships.nic_connected_to_network_security_group
      target: network_security_group
    - type: cloudify.azure.relationships.nic_connected_to_ip_configuration
      target: kubernetes_node_host_nic_ip_cfg

  kubernetes_node_host_nic_ip_cfg:
    type: cloudify.azure.nodes.network.IPConfiguration
    properties:
      location: { get_secret: location }
      azure_config: *azure_config
      retry_after: { get_input: retry_after }
      resource_config:
        privateIPAllocationMethod: Dynamic
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group
    - type: cloudify.azure.relationships.ip_configuration_connected_to_subnet
      target: subnet

  subnet:
    type: cloudify.azure.nodes.network.Subnet
    properties:
      resource_group_name: { get_secret: mgr_resource_group_name }
      name: { get_secret: mgr_subnet_name }
      azure_config: *azure_config
      use_external_resource: true
      location: { get_secret: location }
    relationships:
    - type: cloudify.azure.relationships.contained_in_virtual_network
      target: virtual_network

  virtual_network:
    type: cloudify.azure.nodes.network.VirtualNetwork
    properties:
      resource_group_name: { get_secret: mgr_resource_group_name }
      name: { get_secret: mgr_virtual_network_name }
      azure_config: *azure_config
      use_external_resource: true
      location: { get_secret: location }
    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group

  storage_account:
    type: cloudify.azure.nodes.storage.StorageAccount
    properties:
      name: { get_input: node_storage_account_id }
      location: { get_secret: location }
      azure_config: *azure_config
      use_external_resource: true

    relationships:
    - type: cloudify.azure.relationships.contained_in_resource_group
      target: resource_group

  resource_group:
    type: cloudify.azure.nodes.ResourceGroup
    properties:
      name: {concat:[{get_input: resource_prefix},arg,{get_input: resource_suffix}]}
      location: { get_secret: location }
      azure_config: *azure_config
      use_external_resource: true

groups:
  k8s_node_group:
    members:
      - kubernetes_node_host_nic_ip_cfg
      - kubernetes_node_host_nic
      - k8s_node_host

policies:
  kubernetes_node_vms_scaling_policy:
    type: cloudify.policies.scaling
    properties:
      default_instances:  1
    targets: [k8s_node_group]

outputs:
  deployment-type:
    description: Deployment Type, Needed In order to determine if the kubernetes host is normal node or load balancer
    value: node

  deployment-node-data-type:
    description: Cloudify node type needed in kubernetes cloudify provider
    value: cloudify.nodes.ApplicationServer.kubernetes.Node